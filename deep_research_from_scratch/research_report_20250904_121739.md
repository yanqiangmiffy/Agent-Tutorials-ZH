# Google Gemini 与 OpenAI 深度研究智能体在生物医学研究中的应用比较

## 1 概述

基于对Google Gemini和OpenAI深度研究智能体的全面分析，本报告提供了两者在学术研究应用方面的详细比较，特别关注生物医学领域的专业需求。评估涵盖了功能特性、性能表现、应用场景、成本可用性以及具体需求维度，包括文献分析能力、实验设计建议、数据解释能力、专业可靠性和多模态能力。研究综合了官方技术文档、学术性能基准测试、用户案例研究和成本分析报告，以及生物医学研究者的实际使用反馈。

## 2 Google Gemini 深度研究能力评估

### 2.1 功能特性

Google Gemini，特别是其Med-Gemini变体，专为生物医学研究设计，具备强大的多模态数据处理能力。Med-Gemini能够处理文本、图像、视频和电子健康记录等多模态数据，在MedQA美国医学执照考试式基准测试中达到91.1%的准确率，创下新纪录[1]。Gemini 2.5 Pro提供Deep Research深度研究助手功能，支持100万token上下文窗口，并计划扩展到200万token[3]。

在数据分析与假设生成方面，Google Research开发了基于Gemini 2.0的"AI co-scientist"多智能体系统，专门帮助生物医学研究人员生成研究假设和提案。该系统允许科学家输入研究目标、想法和参考文献，然后使用互联网资源进行"self-improving loop"自我改进循环来优化输出。人类生物医学研究人员评估该系统并评价其高于其他非专业AI系统，指出其具有更大的影响潜力和新颖性[1]。

### 2.2 性能表现

在准确性表现方面，Gemini在医学诊断准确性上前10位鉴别诊断列表中包含正确诊断的比例为76.5%（300/392）[1]。在专业基准测试中，Gemini 2.5 Pro在GPQA（研究生级物理问题评估）上取得84%成绩，显著优于GPT-4o的46%[3]。在MMMU基准测试中达到81.7%，在SWE-Bench基准测试中达到63.8%[3]。

然而，Gemini也存在一些可靠性问题。所有系统都出现了不适当的疾病命名错误，包括过时或拼写错误的术语[1]。Gemini Advanced更不愿意回答医学问题，需要更多提示才能响应，响应率为73.8%，而ChatGPT 4.0直接响应率为89.2%[3]。

### 2.3 多模态能力

Gemini具有原生多模态功能，能够理解和处理文本、图像、音频、PDF和视频等不同数据类型[5]。专业医疗多模态版本包括：
- Med-Gemini-2D：处理2D医学图像
- Med-Gemini-3D：处理3D扫描如CT成像，生成的放射学报告中有超过一半被确定与放射科医师的建议一致
- Med-Gemini-Polygenic：首个从基因组数据进行疾病预测的语言模型[1]

### 2.4 成本与可用性

Google Gemini提供多种访问方式：
- 免费版本：Gemini Pro，基本多模态功能，支持文本、语音、图像输入和基本文档分析[4]
- 付费版本：Gemini Advanced通过Google One AI Premium套餐提供，价格为每月19.99美元，包含完整Gemini 1.5 Pro访问权限、Google应用（Gmail、Docs、Sheets、Slides）的AI功能集成、2TB Google Drive存储空间、NotebookLM Plus研究笔记工具[4]

## 3 OpenAI 深度研究智能体评估

### 3.1 功能特性

OpenAI深度研究智能体能够自动化多步骤的互联网研究，发现、推理并整合来自网络的见解[2][3]。它生成全面、经过深思熟虑且精心引用的文献综述，输出完全记录，带有清晰的引用和思维摘要[2][3]。该智能体由专门的o3模型驱动，针对网页浏览和数据分析优化，能够处理文本、图像和PDF文件，并使用Python工具绘制图表和分析数据[2][3]。

### 3.2 性能表现

在性能基准测试中，OpenAI深度研究智能体在"Humanity's Last Exam"测试中获得26.6%的准确率（评估专家级问题的广泛学科）[2][3]。在GAIA基准测试中达到新的最先进水平（SOTA），评估真实世界问题[2][3]。幻觉事实率显著低于现有ChatGPT模型，但有时仍会产生幻觉事实或错误推断[2][3]。

实际案例显示，在日本智能手机市场份额分析中出现重大错误：声称69% iOS/31% Android vs 实际监管数据47% iOS/53% Android[4]。根本限制在于LLM基于训练数据预测下一个token而非真正理解内容，准确率即使从85%提高到90%仍不足用于专业研究，因任何错误需验证整个输出[4]。

### 3.3 多模态能力

OpenAI深度研究智能体能够处理文本、图像和PDF文件，在互联网上搜索、解释和分析大量多模态内容，支持用户上传文件[2][3]。

### 3.4 成本与可用性

OpenAI于2025年2月2日推出深度研究功能，由o3模型驱动，针对网页浏览和数据分析优化[2][3]。使用限制为：
- Pro用户：每月250次查询（约$20/月）
- Plus/Team/Enterprise/Edu用户：每月25次查询
- 免费用户：每月5次查询[2][3]

## 4 综合比较分析

### 4.1 文献分析能力对比

Gemini在引文精确度方面显著优于GPT-4，其引文正确率达到77.2%，准确率为68.0%，而GPT-4的正确率为54.0%，准确率为49.2%（p < 0.001）[1]。GPT-4生成了更长的引言（平均332.4词 vs Gemini的256.4词，p < 0.001），但包含了更多未引用的事实和假设（1.6次 vs 1.2次，p = 0.001）[1]。

OpenAI Deep Research采用高度迭代的实时研究过程，需要5-30分钟完成研究，提供实时图表、注释和透明的研究流程[2]。Google Gemini Deep Research采用系统化研究方法，需要5-15分钟，生成结构化的文档报告，适合需要静态但全面文档的战略规划[2]。

### 4.2 实验设计建议能力

Gemini集成强化学习与先进神经架构，旨在通过结合语言理解和推理能力来推动AI边界[4]。OpenAI以其GPT系列闻名，专注于设计用于生成类人文本、代码甚至图像的大型语言模型（LLMs）[4]。Gemini的集成强化学习和多模态能力通常在需要推理和上下文理解的任务上产生卓越性能[4]。

### 4.3 数据解释能力

ChatGPT-4和Gemini在英语中的表现均优于阿拉伯语，ChatGPT-4在正确率和CLEAR评分方面始终优于Gemini[3]。英语表现：ChatGPT-4正确率80% vs Gemini 62.5%[3]。阿拉伯语表现：ChatGPT-4正确率65% vs Gemini 55%[3]。两种AI在低阶认知领域表现更好[3]。

### 4.4 专业可靠性

两种模型都产生了伪造证据，限制了它们在参考文献搜索中的可靠性[1]。幻觉率数据显示：GPT-3.5为39.6%，GPT-4为28.6%，Bard为91.4%[6]。GPT-5将幻觉率大幅降低至1.4%，优于GPT-4（1.8%）和GPT-4o（1.49%）[5]。研究强调了验证AI生成学术内容的必要性[1]。

### 4.5 多模态能力

Gemini AI由Google DeepMind开发，强调多模态AI（处理文本、图像、音频和视频）、AI对齐（符合人类价值观）和复杂推理能力[2]。Gemini采用多模态方法，处理各种数据格式包括文本、图像和音频，并专注于解决医疗保健、机器人和自主系统等领域的复杂现实世界挑战[2]。OpenAI主要关注文本生成和快速部署的商业应用，而Gemini专注于多模态数据处理和长期研究[2]。

### 4.6 成本效益分析

Google Gemini Deep Research每月仅需20美元，而OpenAI Deep Research对Pro用户显著更贵，为每月200美元[2]。对于每个Gemini文本提示，AI推理现在消耗0.24 Wh，与一年前相比，能源消耗减少了33倍，碳足迹降低了44倍[5]。OpenAI Deep Research是深度结构化分析的最佳选择，但成本高且处理时间长[2]。Google Gemini Deep Research仍然是偏好直接研究输出且价格更低的用户的强大竞争者[2]。

### 4.7 学术机构采用情况

90%的教职员工现在使用AI工具进行教学和研究活动[5]。尽管采用广泛，只有30%的教师接受过正式的AI培训[5]。自2022年以来，AI研究出版物增长了400%[5]。85%的大学制定了AI政策，但50%面临预算限制[5]。ChatGPT主要用于一般研究（36-37%）、学术研究（18-19%）和编程（14-15%）[5]。65%的营销人员和63%的开发人员定期使用[5]。

### 4.8 生物医学领域专业性能

Gemini在生成可信医学研究引文方面表现更好[1]。ChatGPT-4和Gemini在病毒学多选题（MCQ）中英语和阿拉伯语回答的表现对比显示，ChatGPT-4在正确率和CLEAR评分方面始终优于Gemini[3]。两种AI模型在英语中的表现均优于阿拉伯语[3]。研究结果显示，Gemini和ChatGPT-4都在需要高级批判性思维和问题解决技能的高阶认知MCQ方面遇到困难[3]。

## 5 结论与建议

基于全面分析，Google Gemini和OpenAI深度研究智能体在生物医学研究应用中各有优势。Gemini在医学专业内容处理、引文准确性和多模态能力方面表现更佳，特别适合生物医学文献分析和诊断支持任务。其成本效益更高，每月20美元的定价使其更适合长期学术使用。OpenAI在一般研究任务、英语内容生成和实时研究过程方面表现更好，幻觉率更低，但成本显著更高。

对于生物医学研究机构，推荐根据具体需求选择：如果需要处理专业医学文献、多模态数据和需要高引文准确性，Gemini是更好的选择；如果注重一般研究能力、实时分析过程和较低幻觉率，OpenAI可能更合适。无论选择哪种工具，都需要研究者进行人工验证和结果审核，特别是在专业医学领域。

### 来源

[1] Advancing medical AI with Med-Gemini - Google Research: https://research.google/blog/advancing-medical-ai-with-med-gemini/

[2] Introducing deep research - OpenAI: https://openai.com/index/introducing-deep-research/

[3] Google Gemini Advanced 2025 - Baytech Consulting: https://www.baytechconsulting.com/blog/google-gemini-advanced-2025

[4] Google Gemini Pricing Explained: How Much Does it Cost? - AI Tools: https://www.godofprompt.ai/blog/google-gemini-pricing?srsltid=AfmBOoq3gftc_vUHH7VFsUhwK1lIT0lG7ELIrBlcaC2q-raw1m0X7AOC

[5] Gemini's Performance in Academic Writing: User Feedback and Analysis: https://www.arsturn.com/blog/delving-into-user-feedback-on-geminis-performance-for-academic-writing-research-tasks

[6] Making AI Generative for Higher Education: https://sr.ithaka.org/publications/making-ai-generative-for-higher-education/

[7] Performance of Advanced Large Language Models (GPT-4o, GPT-4, Gemini 1.5 Pro, Claude 3 Opus) on the Japanese National Medical Examination: A Comparative Study: https://www.medrxiv.org/content/10.1101/2024.07.09.24310129v1.full-text

[8] A comparative study of openAI's GPT-4 and Google's gemini - PubMed: https://pubmed.ncbi.nlm.nih.gov/39667055/

[9] OpenAI vs Google: Who Does Deep Research Better?: https://www.analyticsvidhya.com/blog/2025/02/openai-vs-google-who-does-deep-research-better/

[10] The performance of OpenAI ChatGPT-4 and Google Gemini in ...: https://bmcresnotes.biomedcentral.com/articles/10.1186/s13104-024-06920-7